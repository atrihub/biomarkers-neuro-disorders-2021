<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Biostatistics for Fluid Biomarkers</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.6/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: middle, center

# Biostatistics for Fluid Biomarkers

Michael Donohue, PhD

University of Southern California

### Biomarkers in Neurodegenerative Disorders

University of Gothenburg

May 26, 2021


  




.pull-left[

&lt;img src="./images/atri.png" width="57%"  style="display: block; margin: auto;" /&gt;

]


.pull-right[

&lt;img src="./images/actc_logo.png" width="47%"  style="display: block; margin: auto;" /&gt;

]

---

# Course Overview

.large[
Topics:

- 9:00 - 9:50 -- Biostatistics for Fluid Biomarkers
- 10:00 - 10:50 -- Biostatistics for Imaging Biomarkers
- 11:00 - 11:50 -- Modeling Longitudinal Data

Emphases:

- Visualization 
- Demonstrations using R, code available from:
  - [https://github.com/atrihub/biomarkers-neuro-disorders-2021](https://github.com/atrihub/biomarkers-neuro-disorders-2021)
]

---

# Session 1 Outline

.large[
- Batch Effects
- Experimental Design (Sample Randomization)
- Statistical Models for Assay Calibration/Quantification
- Classification (Supervised Learning)
  - Logistic Regression
  - Binary Trees
  - Random Forest
- Mixture Modeling (Unsupervised Learning)
  - Univariate
  - Bivariate
]

---

class: inverse, middle, center

# Batch Effects

---

# Batch Effects: Boxplot



&lt;img src="fluid_fig/batch_data_plot-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Coefficient of Variation

.pull-left[

&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; batch &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; N &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SD &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SD/Mean = CV (%) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 790 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 379 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 48.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 925 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 299 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 32.4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 725 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 53.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 951 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 332 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 690 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 312 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 45.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 867 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 349 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 837 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 446 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 53.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 914 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 348 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38.1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 883 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 763 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 266 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 34.8 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

.pull-right[

- Coefficient of Variation (CV) = SD/Mean
- Often used for quality control (reject batch with CV &gt; `\(x\)`)

]

---

# Testing for Batch Effects


```r
anova(lm(Biomarker ~ batch, batch_data))
Analysis of Variance Table

Response: Biomarker
           Df   Sum Sq Mean Sq F value  Pr(&gt;F)    
batch       9  3573109  397012    3.37 0.00051 ***
Residuals 490 57758046  117874                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

* Batch explains a significant amount of the variation in this simulated data
* R note: `batch` variable must be a `factor`, not `numeric` (otherwise, you will get a batch slope)

---

# Batch effects: Confounds

&lt;img src="fluid_fig/batch_confounds-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

Suppose we have groups of interest (say, active vs placebo) that we would like to compare.

Do we see an problem here?

---

class: inverse, middle, center

# Experimental Design for Fluid Biomarkers

---

# Randomized assignment of samples to plates

&lt;img src="fluid_fig/batch_randomized-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

If we have both groups represented in each batch, we can disentangle batch effects
and group effects

One way to ensure this, is to randomize samples to batches

---

# Experimental Design for Fluid Biomarkers

.large[
- Randomize samples to batches/plates
- Longitudinally collected samples (samples collected over time on same individual):
  - If batch effects are expected to be larger than storage effects, consider randomizing *individuals* to batches
  - (Keep all samples from individual on the same plate)
- Randomization can be stratified to ensure important factors (e.g. treatment group, age, APOE `\(\epsilon4\)`) are balanced
]

---

# Sample Randomization

We use an `R` package [SRS](https://github.com/atrihub/SRS) ("Subject Randomization System"), which we have modified to deal with the constraints of plate capacity, and keeping samples from the same subject together.

(Note this is different than the `SRS` package on CRAN)



&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Subject ID &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Num. of samples &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Group &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Age &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Plate &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 11 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Sample Randomization

.pull-left[

&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Plate &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Num. samples &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

.pull-right[

- Number of young and old well balanced across the 13 plates
- Number of samples per plate is also reasonable (plate capacity was set at 30 samples)

]

---

class: inverse, middle, center

# Calibration

---

# Calibration

.large[

- Calibration: developing a map from "raw" assay responses to concentrations (ng/ml) using samples of *known* concentrations
- We will explore some approaches to calibration with methods from the `R` package `calibFit` (Haaland, et al., 2011; Davidian, et al., 1990)
- The package includes some example data:
  - High Performance Liquid Chromatography (HPLC) and 
  - Enzyme Linked Immunosorbent Assay (ELISA)
- These examples are taken straight from the package vignette

]

???

The package is not actively maintained, so you must install the package from the CRAN archive

---

# Calibration

.pull-leftWider[

&lt;img src="fluid_fig/calibFit_fits-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-rightNarrower[

- *Calibration* is *inverse regression* in which these fitted curves would be used to map assay responses from samples of unkown concentration (vertical axis) to concentration values (horizontal axis).
- Both fits exhibit *heteroscedasticity*: the error variance is not constant with respect to Concentration
- Most models assume *homoscedasticity*, or constant error variance.

]

---

# Residuals (Response - Fitted values)

&lt;img src="fluid_fig/calibFit_residuals-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Typical Regression

Typically, regression models are of the form: 

`\begin{equation}
Y_{i}=f(x_i,\beta)+\epsilon_{i}, 
\end{equation}`

where:

- `\(Y_{i}\)` is the observed response/outcome for `\(i\)`th individual ( `\(i=1,\ldots,n\)` ) 
- `\(x_i\)` are covariates/predictors for `\(i\)`th individual
- `\(\beta\)` are regression coefficients to be estimated
- `\(f(\cdot,\cdot)\)` is the model (assumed "known" or to be estimated)
  - In linear regression `\(f(x_i,\beta)=x_i\beta\)`
- `\(\epsilon_i\)` is the residual error
- We assume `\(\epsilon\sim\mathcal{N}(0,\sigma^2)\)` 
- `\(\sigma\)` is the *constant* standard deviation (*homoscedastic*)

If the standard deviation is not actually constant (*heteroscedastic*), estimates might be unreliable.


---

## Ordinary Least Squares: minimizing the sum of squared residuals

&lt;video width="100%"  controls loop&gt;&lt;source src="fluid_fig/regression-movie.webm" /&gt;&lt;/video&gt;

`\(^*\)` RSS = Residual sum of squares, or `\(\sum_i (\textrm{Observed}_i-\textrm{Fitted}_i)^2\)`

---

# Modeling Heteroscedastic Errors

The `calibFit` package includes models of the form: 

`\begin{equation}
Y_{ij}=f(x_i,\beta)+\sigma g(\mu_i,z_i,\theta) \epsilon_{ij}, 
\end{equation}`

where,

- `\(Y_{ij}\)` are observed assay values/responses for `\(i\)`th individual ( `\(i=1,\ldots,n\)` ), `\(j\)`th replicate
- `\(g(\mu_i,z_i,\theta)\)` is a function that allows the variances to depend on:
  - `\(\mu_i\)` (the mean response `\(f(x_i,\beta)\)`), 
  - covariates `\(z_i\)`, and 
  - a parameter ("known" or unknown) `\(\theta\)`.
- `\(\epsilon_{ij}\sim\mathcal{N}(0,1)\)` 

In particular, `calibFit` implements the Power of the Mean (POM) function

`\begin{equation}
g(\mu_i,\theta) = \mu_i^{2\theta}
\end{equation}`

which results in 

`\begin{equation}
\operatorname{var}(Y_{ij}) = \sigma^2\mu_i^{2\theta}
\end{equation}`

???

allowing the variance to depend on the mean.

---

# "Homogenized" Residuals From Fits with POM



&lt;img src="fluid_fig/calibFit_pom_residuals-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# HPLC Calibration With/Without POM Variance

&lt;img src="fluid_fig/calib_hplc_pom-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

The mean does not change much, but we get more accurate 95% confidence bands

---

# Elisa Calibration With/Without POM Variance

&lt;img src="fluid_fig/calib_elisa_pom-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Calibrated Estimates for Each Sample

.pull-left[

&lt;img src="fluid_fig/calibrated1-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="fluid_fig/calibrated2-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

???

* MDC is Minimum Detectable Concentration, which we'll define on the next slide

---

# Calibration Statistics

Assuming calibration curve `\(f\)`, mapping concentrations to assay responses, is increasing, we define the following terms.

**Minimum Detectable Concentration (MDC)**: The lowest concentration where the curve is increasing, or:

  `$$x_{\textrm{MDC}} = \min\{x : f(x, \beta) &gt; \textrm{UCL}_0\}$$`
  
  where `\(\textrm{UCL}_0\)` is the upper confidence limit at 0

**Reliable Detection Limit (RDL)**: The lowest concentration that has a high probability of producing a response that is significantly greater than the response at 0, or 
  
`$$x_{\textrm{RDL}} = \min\{x : \textrm{LCL}_x &gt; \textrm{UCL}_0 \}$$`

**Limit of Quantitization (LOQ)**: The lowest concentration at which the coefficient of variation is less than a fixed percent (default is 20% in the `calibFit` package).

---

class: inverse, middle, center

# Supervised Learning

## Classification

---

# Classification

.pull-leftWider[

&lt;img src="fluid_fig/classification-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-rightNarrower[

- Data from [adni.loni.usc.edu](adni.loni.usc.edu)
- CSF Abeta 1-42 and t-tau assayed using the automated Roche Elecsys and cobas e 601 immunoassay analyzer system
- Filter time points associated with first assay, and ignore subsequent time points
- We'll ignore MCI and focus on CN vs Dementia
- Values greater than the upper limit of detection have been assigned the limit

]

---

# Classification

&lt;img src="fluid_fig/classification_no_mci-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Reciever Operatoring Characteristic (ROC) Curves

.pull-left[

&lt;img src="fluid_fig/ROC_abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[

For each potential threshold applied to CSF `\(\textrm{A}\beta 42\)`, 
we calculate:
- Sensitivity: True Positive Rate = TP/(TP+FN)
- Specificity: True Negative Rate = TN/(TN+FP)

This traces out the ROC curve.

A typical summary of a classifier's performance is the
Area Under the Curve (AUC)

AUC=0.831 in this case, with 95% CI ( 0.798, 0.865 )

AUCs close to one indicate good performance.

The threshold shown here maximizes the distance between the curve
and the diagonal line (chance) (Youden, 1950)

]

???

Sensitivity is a measure of how well we are detecting positive cases

Specificity is a measure of how well we are detecting controls or negative cases

Youden's index gives equal weight to false positives and false negatives (not necessarily appropriate)

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_abeta_tau-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                  | 95% CI                       | P-value `\(^*\)` |
| ---------------------- |:--------------------:| ----------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.831    | 0.798, 0.865    |              |
| Tau                    | 0.785      | 0.748, 0.822      |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.899 | 0.874, 0.925 |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin, et al., 2011)

So the ratio of Tau / `\(\textrm{A}\beta\)` shows the best discrimination of NC from Dementia cases.



]

---

# Youden's Cutoff for Tau / `\(\textrm{A}\beta\)` Ratio

&lt;img src="fluid_fig/abeta_tau_scatter_youden-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

Line is Tau = 0.394 `\(\times\)` Abeta, depicting Youden's cutoff (maximizes sensitivity + specificity - 1)

???

Youden's cutoff maximizing sensitivity + specificity - 1 is appropriate if sensitivity and specificity are equally important

---

# Logistic Regression

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Coefficient &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.889 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.133 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -6.68 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(ABETA) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.593 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.150 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -10.63 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(TAU) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.256 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.140 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.97 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

`$$\log\big(\frac{p}{1-p}\big) = \hat\gamma_0 + A\beta_z \hat\gamma_{A\beta} + \textrm{tau}_z \hat\gamma_{\textrm{tau}}$$`
where `\(\hat\gamma\)` are regression coefficients.

---

# Logistic Regression Predicted Probabilities

&lt;img src="fluid_fig/logistic_pred_prob-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

line again depicts Youden's cutoff

---

# Ratio Contours

&lt;img src="fluid_fig/ratio_gradient-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

by using ratio's we're simplifying the bivariate scatter by assuming all dots along
these lines intersecting (0,0) are equivalent

dashed line has slope 1
---


# Logistic Regression Predicted Probability Contours

&lt;img src="fluid_fig/ratio_gradient_logistic-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

in contrast, logistic regression assumes the predicted probability gradient follows these
parallel lines

lines now are where predicted probabilities from logistic regression are constant

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_logistic-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                      | 95% CI                           | P-value `\(^*\)` |
| ---------------------- |:------------------------:| --------------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.831        | 0.798, 0.865        |              |
| Tau                    | 0.785          | 0.748, 0.822          |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.899     | 0.874, 0.925     |  &lt;0.001      |
| Logisitic model        | 0.898 | 0.872, 0.923 |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin, et al., 2011)

Logistic model ROC is very similar to Tau/ `\(\textrm{A}\beta\)` ratio ROC.



]

---

# Logistic Regression with Age and APOE

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Coefficient &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.123 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.173 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -6.49 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(ABETA) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.434 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.160 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -8.98 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(TAU) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.194 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.140 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.50 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(I(AGE + Years.bl)) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.138 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.115 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.20 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.230 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; as.factor(APOE4)1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.368 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.252 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.46 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.144 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; as.factor(APOE4)2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.261 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.452 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.79 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.005 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



This model does not provide much better ROC, either.

---

# Regression Trees

&lt;img src="fluid_fig/tree1-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

Hothorn, et al. (2006)

???

Regression trees use recursive partitioning to classify data into more and more homogeneous subgroups

---

# Tree-based Methods

&lt;img src="fluid_fig/tree2-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

With this shallow tree, we end up with these four partitions of the Abeta-by-Tau scatter

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_rf-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                      | 95% CI                           | P-value `\(^*\)` |
| ---------------------- |:------------------------:| --------------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.831        | 0.798, 0.865        |              |
| Tau                    | 0.785          | 0.748, 0.822          |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.899     | 0.874, 0.925     |  &lt;0.001      |
| Logisitic model        | 0.898 | 0.872, 0.923 |  &lt;0.001      |
| Binary Tree            | 0.884     | 0.856, 0.912     |  &lt;0.001      |
| Random Forest          | 0.946       | 0.93, 0.961       |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin, et al., 2011)

Random Forests (Breiman, 2001; Hothorn, et al., 2006) re-fit binary trees on random subsamples
of the data, then aggregate resulting trees into a "forest". This results in smoother predictions and a smoother ROC curve.



]

---

class: inverse, middle, center

# Unsupervised Learning

## Mixture Modeling

---

# Unsupervised Learning

.large[
- The classification techniques we just reviewed can be thought of as *Supervised Learning* in which we attempt to learn known "labels" (CN, Dementia).
- *Mixture Modeling* is type of *Unsupervised Learning* technique in which we try to identify clusters of populations which appear to be arising from different distributions
- Don't confuse *Mixture Models* with *Mixed-Effects Models* (which we'll discuss later)
  - Think: "Mixture of Distributions"
]

---

# Distribution of ABETA

&lt;img src="fluid_fig/density_Abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

- Distribution is bimodal
- Can we identify the two sub-distributions?
- We'll explore with `mixtools` package (Benaglia, et al., 2009)

---

# Distribution of ABETA



&lt;img src="fluid_fig/mixture_distribution_Abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

mixture models provide latent class membership probabilities, such as these 

---

# Posterior Membership Probabilities

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Abeta &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Prob. Abnormal &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Prob. Normal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1033 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.580 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.420 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1036 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.567 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.433 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1044 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.533 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.467 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1048 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.516 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.484 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1061 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.460 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.540 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1071 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.417 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.583 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1071 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.417 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.583 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1072 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.413 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.587 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Bivariate Density



&lt;iframe src="bvdensity_csf_tau.html" width="100%" height="500" id="igraph" scrolling="no" seamless="seamless" frameBorder="0"&gt; &lt;/iframe&gt;

---

# Bivariate Density Contour Plot

&lt;img src="fluid_fig/bv_kernel_density-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Bivariate Mixture Model Posterior Probabilities

.pull-left[
&lt;img src="fluid_fig/mvmix_post_prob-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="fluid_fig/mvmix_density-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;
]

???

line on the left is still Youden's cutoff for the ratio

Contours are confidence ellipses at 99%, 95%, and 90% just to help see the shape of the estimated distributions


---

# Summary

.large[
- Batch Effects
- Experimental Design (Sample Randomization)
- Statistical Models for Assay Calibration/Quantification
- Classification (Supervised Learning)
  - Logistic Regression
  - Binary Trees
  - Random Forest
- Mixture Modeling (Unsupervised Learning)
  - Univariate
  - Bivariate
]

---

# References

Benaglia, T., D. Chauveau, D. R. Hunter, and D. Young (2009).
"mixtools: An R Package for Analyzing Finite Mixture Models". In:
_Journal of Statistical Software_ 32.6, pp. 1-29. URL:
[http://www.jstatsoft.org/v32/i06/](http://www.jstatsoft.org/v32/i06/).

Breiman, L. (2001). "Random forests". In: _Machine learning_ 45.1, pp.
5-32.

Davidian, M. and P. D. Haaland (1990). "Regression and calibration with
nonconstant error variance". In: _Chemometrics and Intelligent
Laboratory Systems_ 9.3, pp. 231-248.

Haaland, P., D. Samarov, and E. McVey (2011). _calibFit: Statistical
models and tools for assay calibration_. R package version 2.1.0. URL:
[https://CRAN.R-project.org/package=calibFit](https://CRAN.R-project.org/package=calibFit).

Hothorn, T., P. Buehlmann, S. Dudoit, A. Molinaro, and M. Van Der Laan
(2006). "Survival Ensembles". In: _Biostatistics_ 7.3, pp. 355-373.

Hothorn, T., K. Hornik, and A. Zeileis (2006). "Unbiased Recursive
Partitioning: A Conditional Inference Framework". In: _Journal of
Computational and Graphical Statistics_ 15.3, pp. 651-674.

Robin, X., N. Turck, A. Hainard, N. Tiberti, F. Lisacek, J. Sanchez,
and M. MÃ¼ller (2011). "pROC: an open-source package for R and S+ to
analyze and compare ROC curves". In: _BMC Bioinformatics_ 12, p. 77.

Youden, W. J. (1950). "Index for rating diagnostic tests". In: _Cancer_
3.1, pp. 32-35.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLanguage": ["r", "css", "yaml"],
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
